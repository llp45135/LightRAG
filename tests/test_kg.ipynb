{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 客规Insert\n",
    "This notebook replicates the functionality of the `test_ollama.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lightrag import LightRAG, QueryParam\n",
    "from lightrag.llm.openai import gpt_4o_mini_complete, gpt_4o_complete, openai_embed\n",
    "from lightrag.llm.ollama import ollama_model_complete, ollama_embed\n",
    "from lightrag.llm.siliconcloud import siliconcloud_embedding\n",
    "from lightrag.utils import EmbeddingFunc\n",
    "from lightrag.operate import chunking_markdown_hierarchical\n",
    "import asyncio\n",
    "from lightrag import LightRAG, QueryParam\n",
    "from lightrag.llm.openai import openai_complete_if_cache\n",
    "from lightrag.llm.siliconcloud import siliconcloud_embedding\n",
    "from lightrag.utils import EmbeddingFunc\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Uncomment the below two lines if running in a jupyter notebook to handle the async nature of rag.insert()\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = \"./KG\"\n",
    "\n",
    "if not os.path.exists(WORKING_DIR):\n",
    "    os.mkdir(WORKING_DIR)\n",
    "\n",
    "# 在导入部分添加\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 在代码的开头加载环境变量\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed8b354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def llm_model_func(\n",
    "    prompt, system_prompt=None, history_messages=[], keyword_extraction=False, **kwargs\n",
    ") -> str:\n",
    "    return await openai_complete_if_cache(\n",
    "        \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "        # \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\",\n",
    "        # \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\",\n",
    "        prompt,\n",
    "        system_prompt=system_prompt,\n",
    "        history_messages=history_messages,\n",
    "        api_key=os.getenv(\"SILICONFLOW_API_KEY\"),\n",
    "        base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "async def embedding_func(texts: list[str]) -> np.ndarray:\n",
    "    return await siliconcloud_embedding(\n",
    "        texts,\n",
    "        model=\"netease-youdao/bce-embedding-base_v1\",\n",
    "        api_key=os.getenv(\"SILICONFLOW_API_KEY\"),\n",
    "        max_token_size=512,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3334181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function test\n",
    "async def test_funcs():\n",
    "    result = await llm_model_func(\"How are you?\")\n",
    "    print(\"llm_model_func: \", result)\n",
    "\n",
    "    result = await embedding_func([\"How are you?\"])\n",
    "    print(\"embedding_func: \", result)\n",
    "\n",
    "\n",
    "asyncio.run(test_funcs())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Choose the model here\n",
    "# model_choice = \"ollama\"  # Options: \"ollama\", \"openai\"\n",
    "\n",
    "# llm_model_func = ollama_model_complete\n",
    "# embedding_func = EmbeddingFunc(\n",
    "#     embedding_dim=1024,\n",
    "#     max_token_size=8192,\n",
    "#     func=lambda texts: ollama_embed(\n",
    "#         texts,\n",
    "#         embed_model=\"bge-m3:latest\"\n",
    "#     )\n",
    "# )\n",
    "# rag = LightRAG(\n",
    "#     working_dir=WORKING_DIR,\n",
    "#     llm_model_func=llm_model_func, \n",
    "#     llm_model_name='qwen2.5:7b-instruct-q4_K_M',\n",
    "#     embedding_func=embedding_func,\n",
    "#     llm_model_max_token_size=32768,\n",
    "#     llm_model_kwargs={\"host\": \"http://localhost:11434\", \"options\": {\"num_ctx\": 32768}},\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec8e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = LightRAG(\n",
    "    working_dir=WORKING_DIR,\n",
    "    chunking_mode=\"markdown\",\n",
    "    llm_model_func=llm_model_func,\n",
    "    embedding_func=EmbeddingFunc(\n",
    "        embedding_dim=768, max_token_size=512, func=embedding_func\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Inserting 1 to doc_status\n",
      "INFO:lightrag:Stored 1 new unique documents\n",
      "INFO:lightrag:Number of batches to process: 1.\n",
      "INFO:lightrag:Start processing batch 1 of 1.\n",
      "INFO:lightrag:Inserting 1 to doc_status\n",
      "INFO:lightrag:Inserting 8 to chunks\n",
      "INFO:lightrag:Inserting 1 to full_docs\n",
      "INFO:lightrag:Inserting 8 to text_chunks\n",
      "INFO:lightrag:Non-embedding cached missed(mode:default type:extract)\n",
      "INFO:lightrag:Non-embedding cached missed(mode:default type:extract)\n",
      "INFO:lightrag:Non-embedding cached missed(mode:default type:extract)\n",
      "INFO:lightrag:Non-embedding cached missed(mode:default type:extract)\n",
      "INFO:lightrag:Non-embedding cached missed(mode:default type:extract)\n",
      "INFO:lightrag:Non-embedding cached missed(mode:default type:extract)\n",
      "INFO:lightrag:Non-embedding cached missed(mode:default type:extract)\n",
      "INFO:lightrag:Non-embedding cached missed(mode:default type:extract)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Chapter: # 中国铁路广州局集团有限公司关于发布《广州局集团公司重点、团体用票管理办法》的通知\n",
      "Processing Section: ## 广州局集团公司重点、团体用票管理办法\n",
      "Processing Subsection: ### 第一章 总 则\n",
      "Processing Subsection: ### 第二章 合同户管理\n",
      "Processing Subsection: ### 第三章 机动票管理\n",
      "Processing Subsection: ### 第四章 职工乘车证签证管理\n",
      "Processing Subsection: ### 第五章 团体票管理\n",
      "Processing Subsection: ### 第六章 日常台账管理和监督检查\n",
      "Processing Subsection: ### 第七章 附 则\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Inserting 1 to llm_response_cache\n",
      "INFO:lightrag:Non-embedding cached missed(mode:default type:extract)\n",
      "INFO:lightrag:Inserting 1 to llm_response_cache\n",
      "INFO:lightrag:Non-embedding cached missed(mode:default type:extract)\n",
      "INFO:lightrag:Inserting 1 to llm_response_cache\n",
      "INFO:lightrag:Non-embedding cached missed(mode:default type:extract)\n",
      "INFO:lightrag:Inserting 1 to llm_response_cache\n",
      "INFO:lightrag:Non-embedding cached missed(mode:default type:extract)\n",
      "INFO:lightrag:Inserting 1 to llm_response_cache\n",
      "INFO:lightrag:Non-embedding cached missed(mode:default type:extract)\n",
      "INFO:lightrag:Inserting 1 to llm_response_cache\n",
      "INFO:lightrag:Non-embedding cached missed(mode:default type:extract)\n",
      "INFO:lightrag:Inserting 1 to llm_response_cache\n",
      "INFO:lightrag:Inserting 1 to llm_response_cache\n",
      "INFO:lightrag:Inserting 1 to llm_response_cache\n",
      "INFO:lightrag:Non-embedding cached missed(mode:default type:extract)\n",
      "INFO:lightrag:Inserting 1 to llm_response_cache\n",
      "INFO:lightrag:Non-embedding cached missed(mode:default type:extract)\n",
      "INFO:lightrag:Inserting 1 to llm_response_cache\n",
      "INFO:lightrag:Inserting 1 to llm_response_cache\n",
      "INFO:lightrag:Inserting 1 to llm_response_cache\n",
      "INFO:lightrag:Inserting 1 to llm_response_cache\n",
      "INFO:lightrag:Inserting 1 to llm_response_cache\n",
      "INFO:lightrag:Inserting 1 to llm_response_cache\n",
      "INFO:lightrag:Inserting 121 to entities\n",
      "INFO:lightrag:Inserting 80 to relationships\n",
      "INFO:lightrag:New entities or relationships extracted.\n",
      "INFO:lightrag:Inserting 1 to doc_status\n",
      "INFO:lightrag:Completed batch 1 of 1.\n",
      "INFO:lightrag:Writing graph with 856 nodes, 595 edges\n",
      "INFO:lightrag:All Insert done\n"
     ]
    }
   ],
   "source": [
    "with open(\"./kg8.md\") as f:\n",
    "    rag.insert(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = \"广州南、长沙站在一级应急响应和四级应急响应中的标准有哪些不同？\"\n",
    "q = \"客服设施工程静态、动态验收工作内容和要求包括什么\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33605441",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform naive search\n",
    "print(\"naive.....................\")\n",
    "print(rag.query(q, param=QueryParam(mode=\"naive\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform local search\n",
    "print(\"local.....................\")\n",
    "print(rag.query(q, param=QueryParam(mode=\"local\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform global search\n",
    "print(\"global.....................\")\n",
    "print(rag.query(q, param=QueryParam(mode=\"global\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform hybrid search\n",
    "print(\"hybrid.....................\")\n",
    "print(rag.query(q, param=QueryParam(mode=\"hybrid\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform mix search (Knowledge Graph + Vector Retrieval)\n",
    "print(\"mix.....................\")\n",
    "print(rag.query(q, param=QueryParam(mode=\"mix\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
